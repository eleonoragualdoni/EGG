{
    "n_epoch": [2],
    "batch_size": [128],
    "lr": [2.4],
    "use_larc":[true],
    "random_seed": [111],
    "gs_temperature": [5.0],
    "use_augmentations": [true],
    "recv_output_dim": [2048],
    "recv_temperature": [0.1],
    "vocab_size": [1024],
    "contextual_distractors": [true],
    "wandb": [true],
    "wandb_tag": ["contextual_emcomm"]
}
